<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Srinivas Kaza</title>

    <meta name="author" content="Srinivas Kaza">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Srinivas Kaza
                </p>
                <p>I work on <a href="https://starline.google//">Project Starline</a> at Google. My research and engineering interests are related to comptuer graphics, vision, and ML</a>. Before that, I spent time working at <a href="https://www.isee.ai/">isee.ai</a>. I received both my Masters (MEng) and undergraduate degrees from MIT, with a focus on computer graphics.
                </p>
                <p style="text-align:center">
                  <a href="mailto:kazasrinivas3@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=w2OQKAMAAAAJ">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/animatedrng/">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/SrinivasKaza.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/SrinivasKaza.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  My primary interests are related to radiance fields, compression, and computational photography. As part of my research, I hope to create the building blocks needed for fast, robust 3D reconstruction.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/sdf.png" alt="clean-usnob" width="250" height="100">
              </td>
              <td width="75%" valign="middle">  
              <span class="papertitle">Coming (very) soon</span>
              <br>
              <em>SIGGRAPH Asia</em>, 2024 &nbsp
              <br>
              </td>
            </tr>
            
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/db3d_cropped.gif" alt="clean-usnob" width="250" height="150">
              </td>
              <td width="75%" valign="middle">
                <a href="https://dreambooth3d.github.io/">
                  <span class="papertitle">DreamBooth3D: Subject-Driven Text-to-3D Generation</span>
                </a>
                <br>
                <a href="https://amitraj93.github.io/">Amit Raj</a>, <strong>Srinivas Kaza</strong>, <a href="https://poolio.github.io/">Ben Poole</a>, <a href="https://m-niemeyer.github.io/">Michael Niemeyer</a>, <a href="https://natanielruiz.github.io/">Nathaniel Ruiz</a>, <a href="https://bmild.github.io/">Ben Mildenhall</a>, <a href="https://scholar.google.com/citations?user=I2qheksAAAAJ">Shiran Zada</a>, <a href="https://kfiraberman.github.io/">Kfir Aberman</a>, <a href="https://people.csail.mit.edu/mrub/"> Michael Rubenstein </a>, <a href="https://jonbarron.info/">Jonathan Barron</a>, <a href="https://people.csail.mit.edu/yzli/">Yuanzhen Li</a>, <a href="https://varunjampani.github.io/">Varun Jampani</a>
                <br>
                <em>ICCV</em>, 2023 &nbsp
                <br>
                <p>We present DreamBooth3D, an approach to personalize text-to-3D generative models from as few as 3-6 casually captured images of a subject. Our approach combines recent advances in personalizing text-to-image models (DreamBooth) with text-to-3D generation (DreamFusion). We find that naively combining these methods fails to yield satisfactory subject-specific 3D assets due to personalized text-to-image models overfitting to the input viewpoints of the subject. We overcome this through a 3-stage optimization strategy where we jointly leverage the 3D consistency of neural radiance fields together with the personalization capability of text-to-image models. Our method can produce high-quality, subject-specific 3D assets with text-driven modifications such as novel poses, colors and attributes that are not seen in any of the input images of the subject.</p>
              </td>
            </tr>
            
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/sdf.png" alt="clean-usnob" width="250" height="100">
              </td>
              <td width="75%" valign="middle">
                <a href="https://dspace.mit.edu/bitstream/handle/1721.1/124253/1145123039-MIT.pdf?sequence=1&isAllowed=y">
                  <span class="papertitle">Differentiable Volume Rendering using Signed Distance Functions</span>
                </a>
                <br>
                <strong>Srinivas Kaza</strong>
                <br>
                <p>Gradient-based methods are often used in a computer graphics and computer vision context to solve inverse rendering problems. These methods can be used to infer camera parameters, material properties, and even object pose and geometry from 2D images.
                </p>
                <p> One of the challenges that faces differentiable rendering systems is handling visibility terms in the rendering equation, which are not continuous on object boundaries.
We present a renderer that solves this problem by introducing a form of visibility that
is not discontinuous, and thus can be differentiated. This “soft visibility” is inspired by
volumetric rendering, and is facilitated by our decision to represent geometry within
the scene as a signed distance function. We also present methods for performing gradient descent upon distance fields while preserving Lipschitz continuity. Unlike most
differentiable mesh-based renderers, our renderer can optimize between geometry of
different homeomorphism classes in a variety of image-based shape fitting tasks.</p>
              </td>
            </tr>

          </tbody></table>
          
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  I created this website using <a href="https://github.com/jonbarron/website">this template</a> by <a href="https://jonbarron.info/">Jon Barron</a>.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
